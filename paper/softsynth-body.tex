\section{Introduction}

Since the creation of Inductive Program Synthesis (IPS) in the 1970s\cite{Kitzelmann2009}, researchers have been striving to create systems capable of generating programs competitively with human intelligence. Modern IPS methods often trace their roots to the fields of machine learning, logic programming, evolutionary computation and others.

The similarities and differences of these methods have been discussed\cite{Kitzelmann2009}, but their performance is rarely compared on problem sets that could provide concrete insight into the capabilities and limitations of each method.

A demonstrative problem set has been compiled that assess an IPS method's ability to work within a range of levels of abstraction\cite{Gaunt2016}, manipulate a variety of data types, produce complex control structures and produce an arbitrary number of outputs of various forms\cite{Helmuth2015b}.

\todo{We need to define exactly what we mean by ``solution'', since it's different
	for GP and, e.g., MagicHaskeller. GP won't \emph{always} find a solution.}

This investigation is exclusively considering a methods ability to find solutions. Other measures, such as runtime or hardware models, are not thoroughly examined. In order to determine if a method can find solutions to a problem, the problem must first be phrased in its entirety to the method. This is not always possible.

The conclusions drawn from this comparison will speak to the flexibility of each considered method, as well as each method's success rate.

\section{Current State of the Art}

Below are descriptions of the five inductive program synthesis techniques compared in our experiments.

\todo[inline]{Tom: Eddie, feel free to remove citations or text from what I added below if you need space. Most of the citations aren't very important, and the text could be trimmed, if need be.}

\subsection{Flash Fill}

Flash Fill, recently added to Microsoft Excel, uses version-space algebras to perform program synthesis from examples on string manipulation tasks \cite{Gulwani2011}. It was designed to help non-programmers perform repetitive tasks that would otherwise require them to write Excel macro programs. As such, it is able to quickly create simple programs for one-off repetitive tasks in spreadsheet applications for non-programmers \cite{Gulwani:2012:SDM:2240236.2240260, harris2011spreadsheet, Singh:2012:LSS:2212351.2212356, singh2012synthesizing}. Building on the use of version-space algebras for programming by demonstration \cite{lau2003programming}, Flash Fill assumes few example inputs and must make simplifying assumptions about the problem space. In particular, the domain-specific language used here is designed for small string manipulation tasks that an end-user may want to perform without knowing how to program them. Adapting the technique for new domains would require a different domain-specific language that is carefully crafted to meet problem requirements while restrictive enough to allow for quick searching. Each different domain-specific language would also require a new synthesis technique; it is unclear whether Flash Fill will even be able to tackle many general program synthesis problems.

To test Flash Fills performance with our problem set, an Excel spreadsheet with one column per input and one column for output was created for each problem. Each spreadsheet included training data, which had both the input and output column populated, and unseen testing data, which left the output column cells empty. Flash Fill is deterministic and analytic, thus it was only run once per problem on a single data set.

It is not possible to pose tasks to Flash Fill that required multiple outputs. This includes problems that require printing values in addition to returning an output. Asking Flash Fill to generate each output value in separate cell was considered, but this would be two separate tasks and would not be comparable to other the other IPS methods.

\subsection{MagicHaskeller}

MagicHaskeller \cite{katayama2010,Katayama05} synthesizes functional Haskell programs through an exhaustive search of programs with the correct type signatures. It uses a Monte-Carlo algorithm to remove semantically equivalent programs from the search space \cite{Katayama2008}. More recently, it has also integrated an analytic component based on \textsc{Igor2} \cite{kitzelmann2011two}, which allows it to synthesize a greater range of programs than can be found in reasonable time using exhaustive search \cite{katayama2011magichaskeller}. Additionally, a web interface is available running a time-limited version of MagicHaskeller intended as a Haskell teaching tool for new programmers \cite{katayama2013}. These implementations make great use of Haskell's functional instructions, and they perform well on problems that require list manipulations and structural changes. While MagicHaskeller performs very quickly on simple problems without too many examples, it has trouble with problems that require a large number of examples to illuminate the relevant edge cases. Additionally, it seems to have trouble with problems that require conditional control flow.

MagicHaskeller uses specifications in the form of a predicate consisting of example function calls and their desired outputs. To then synthesize a function, MagicHaskeller generates a stream of functions that have the same signature as the example function calls. Thus generated functions have the same number of inputs, the same input types, the same number of outputs, and the same output types.
Generated functions are tested against the input predicate, and a sample of passing functions are presented to the user. The user can then "Exemplify" the suggested solution functions to see how they would behave given a variety of other inputs. If the user cannot find an adequate solution function, more functions can be generated until the entire stream has been processed.

For our experiments, we used the web hosted version of MagicHaskeller. When using the MagicHaskeller web service, all MagicHaskeller users share the same dynamic programming table used for memoization, and the users cannot select which functions are included when searching. Due to MagicHaskeller being hosted on the web, it is difficult to embed MagicHaskeller in other systems.

\begin{figure}
\begin{verbatim}
((f [1, 2, 3] == [0, 1, 2]) && (f [-1, 1] == [-2, 0]))  
\end{verbatim}
\caption{An example predicate that can be supplied to MagicHaskeller. This particular predicate produces a solution to the Decrement problem.}
\label{fig:MHpred}
\end{figure}

Figure \ref{fig:MHpred} shows an example input predicate. Notice that multiple nested predicates can be supplied. MagicHaskeller supports the common primitive data types such as: integers, floats, strings and characters. Vectors and tuples are also supported, witch greatly expands the number of problems that were able to be posed to MagicHaskeller.

MagicHaskeller only allows for the synthesis of functions that produce a single output value. In order to pose question that require multiple outputs, MagicHaskeller was given predicates that specified a tuple as an output. For problems that specify that values should be printed in addition to the output value, it was considered sufficient if MagicHaskeller could synthesis a program that produced a single string containing all printed values (including whitespace and newline) as an element of its output tuple.

\subsection{TerpreT}

TerpreT is a recently developed, probabilistic programming language that is designed for inductive program synthesis \cite{Gaunt2016}. Problems are specified in the TerpreT language, which is then translated into four different back-end inference algorithms: Forward Marginals Gradient Descent (FMGD), Integer Linear Programming (ILP), Satisfiability modulo theories (SMT) and SKETCH.
The TerpreT system attempts to solve IPS problems using these back-end algorithms and returns source code containing the successful parameters found by the successful back-end algorithm, if one is present.

Note that there is currently no publicly available implementation of TerpreT and thus only results on benchmark problems provided by the original authors could be obtained. It would be extremely valuable to compare TerpreT's performance on the rest of the problem set using in this paper once an implementation becomes available.

\subsection{Genetic Programming}

Soon after the rise of evolutionary computation, John R. Koza recognized that evolution could be used for more than optimizing a fixed structure of values. In the 1990s, Koza built upon genetic algorithms in such a way that produced executable programs. This technique, named Genetic Programming (GP), is considered inductive program synthesis because it uses input-output examples (refered to as test cases in the field of GP) to evolve a function. In fact, IPS was one of the origional motivations for creating the field of GP \cite{Koza1992}. 

Genetic Programming works by generating a initial population of random programs. Traditionally these programs are represented as trees where non-leaf nodes each denote a function. The children of each non-leaf node are used as the arguments to their parents. Leaf nodes denote terminal values that could be either a constant or input value. This initial population of random programs then follows the cycle in Figure \ref{fig:evo}  until a solution is found or the run is considered a failure.

\begin{figure}[t]
\centering
\includegraphics[width=0.25\textwidth]{res/EvolutionCycle}
\caption{Evolutionary Computation process.}
\label{fig:evo}
\end{figure}

\subsubsection{PushGP}

Our first comparison genetic program system, PushGP, evolves programs in a Turing complete, stack based language called Push \cite{Spector2002, Spector2005}. Push features separate stacks for each data type, including code. Push programs are lists of instructions and literals. Literals are values that get placed on the stack corrisponding to their type. Instructions are built-in functions that pop values off the stacks, modify them, and push them back on the appropriate stacks. Programs are run through an interpreter, which modifies the stacks. After all instructions and literals have been processed through the interpreter, the final state of the stacks is the output of the program.

PushGP was chosen as a comparison method because of its ability to evolve programs that can do the following:
\begin{itemize}
\item Manipulate all basic data types, including vectors.
\item Return multiple outputs.
\item Utilize iteration, recursion, conditional execution, and other more exotic control structures.
\end{itemize}

Given that the chosen problem set contains general software tasks that require all three of the above listed features, most commonly used Genetic Programming systems would be unable to adequately attempt to find a solution. Recently, there have been some notable exceptions to this that warrant further research.

Implementations of PushGP systems are available in the Clojure programming language\footnote{https://github.com/lspector/Clojush}, as well as a new implementation in Python\footnote{https://github.com/erp12/Pysh}.

\subsubsection{Grammar Guided Genetic Programming (G3P)}

Here's the citation \cite{Forstenlechner:2017:eurogp}.

\todo[inline]{Write me!}

\section{Problems}
\subsection{Basic Execution Models Problems}
The first set of problems were taken from \cite{Gaunt2016} and were intended to demonstrate TerpreT's ability to synthesis programs in a variety of execution models that span multiple levels of abstraction. These execution models are: Turing Machine, Boolean Circuits, Basic Block, and Assembly Language. 

As stated by \cite{Gaunt2016}, the problems in this set progress from more abstract execution models towards models which resemble assembly languages. This makes these problems demonstrative of how a system performs across a variety of low-level domains. 
 
The problems in this set are describes below:

\subsubsection{Invert}

Given a binary string (binary tape), invert all the bits.

\subsubsection{Prepend Zero}

Insert a $0$ in the first index of a binary string and shift all other bits to the right.

\subsubsection{Binary Decrement}

Given an input binary string equal to a positive decimal number, return a binary string equal to the input number decremented by one.

\subsubsection{2-bit Controlled Shift Register}

Given input bit ($r_1$, $r_2$, $r_3$), return the same bits, except swap the order of $r_2$ and $r_1$ if $r_1 == 1$.

\subsubsection{Full Adder}

Given a carry bit, $c_{in}$, and two argument bits, $a$ and $b$ , output a sum bit, $s$, and carry bit, $c_{out}$, such that  $s + 2c_{out} = c_{in} + a_1 + b_1$.

\subsubsection{2-bit Adder}

Given input bits $a_1$, $a_2$, $b_1$, and $b_2$, output $s_1$, $s_2$, and $c_{out}$ such that  $s_1 + 2s_2 + 4c_{out} = a_1 + b_1 + 2(a_2 + b_2)$.

\subsubsection{Access}

Given an input array, $V$, and a positive integer, $i$, return $V_i$. Assume $0 < i < |A|$.

\subsubsection{Decrement}

Given an input array, $V$ return a new array, $U$ such that $U_i = V_i - 1$.


\subsection{General Program Synthesis Benchmark Suite}
The second set of problems used in this comparison was proposed by \cite{Helmuth2015b} in order to provide the field of Genetic Programming with a set of non-trivial benchmark problems.

This problems set included problems that deal with multiple data types, including strings, numbers, boolean and vectors. There are also multiple problems in the set that require multiple output values, or printing certain values to the screen.

Given that the Basic Execution Models problem set is designed to test a systems ability to perform in low-level domains (binary circuits, assembly language, etc), the General Program Synthesis Benchmark Suite is an excellent addition, given that the problems' origins assume a much higher-level implementation (ie. java).

%\subsubsection{Number IO}
%\subsubsection{Small or Large}
%\subsubsection{For Loop Index}
%\subsubsection{Compare String Lengths}
%\subsubsection{Double Letters}
%\subsubsection{Collatz Numbers}
%\subsubsection{Replace Space with Newline}
%\subsubsection{String Differences}
%\subsubsection{Even Squares}
%\subsubsection{Wallis Pi}
%\subsubsection{String Lengths Backwards}
%\subsubsection{Last Index of Zero}
%\subsubsection{Vector Average}
%\subsubsection{Count Odds}
%\subsubsection{Mirror Image}
%\subsubsection{Super Anagrams}
%\subsubsection{Sum of Squares}
%\subsubsection{Vectors Summed}
%\subsubsection{X-Word Lines}
%\subsubsection{Pig Latin}
%\subsubsection{Negative To Zero}
%\subsubsection{Scrabble Score}
%\subsubsection{Word Stats}
%\subsubsection{Checksum}
%\subsubsection{Digits}
%\subsubsection{Grade}
%\subsubsection{Median}
%\subsubsection{Smallest}
%\subsubsection{Syllables}

\section{Limitation of Comparison}

\todo[inline]{Write me!}
The problems described in section 3 were chosen to demonstrate a system's ability to perform general program synthesis tasks. Each system considered in the comparison is designed for different situations which resulted in a difficult comparison.

\subsection{Support For Multiple Outputs}

The benchmark problems we consider have different requirements on their outputs, including some problems that print outputs, some that functionally return outputs, and some that require multiple outputs. If a system does not support printing values, it was considered sufficient to return a single string containing all printed text, including newlines, in addition to the other output values.

Flash Fill only supports populating cells in a single column at once. The only way to produce multiple outputs using Flash Fill would be to generate each output value separately. Solving a problem in multiple parts was considered a fundamentally different IPS task, and thus a variety of problems were considered unable to be fully posed to Flash Fill.

MagicHaskeller also only supports synthesizing programs that produce a single output, however MagicHaskeller supports the tuple data type. Given that elements of a tuple do not have to be of the same data type, it was deemed adequate for MagicHaskeller to produce a single tuple containing all outputs for problems that required multiple outputs. For problems that called for printing values, one of the elements of the output tuple would be a string containing all printed text, including newlines.

\subsection{Supported Data Types}

Many problems in the comparison required the handling of multiple data types, often including vectors.  Excel does not include a native vector or list data structure, and it is not clear what the best way to phrase problems that require vectors to Flash Fill. A string representation of vectors was attempted for some problems. If a problem specifies an input value will be a vector of fixed length, the problem can be posed with each element of the vector in its own cell. If the vector's length is not fixed, this cannot be done, because a tabular structure cannot be formed. If a problem requires a vector output, it cannot be posed to Flash Fill with elements in their own cell because generating each output value would be a separate IPS task. Due to this shortcoming of Flash Fill, there are a number of problems in this comparison that Flash Fill was unable to attempt.

\subsection{Number of Training and Test Cases}

The number of nested predicates that can be given to MagicHaskeller is very limited, and if too many predicates are given the system will produce memory errors. This is a consequence of MagicHaskeller being a web hosted service where resources are shared between all users. Due to this limitation, it was not possible to give MagicHaskeller the same training dataset as the other IPS methods. Although this weakens the presented results, it speaks to the usability and flexibility of the MagicHaskeller system.

\subsection{Access To Systems}

There is not publicly available implementation of TerpreT, and thus it is only known how TerpreT performs on the \emph{Basic Execution Models} problem set. It is unknown how TerpreT would perform on the \emph{General Program Synthesis Benchmark Suite}.

Flash Fill is not open-source, which makes it impossible to modify for new tasks.

\todo[inline]{TODO: Find out of G3P is available.}

\section{Results}

\todo[inline]{Which problems were not able to be posed to certain systems}
\todo[inline]{Which systems performed better on which problems}

\begin{figure}
\begin{tabular}{ r | c c c c }
	& TerpreT & Flash Fill & MH & PushGP \\
	\hline
	Invert & \checkmark & $x$ & \checkmark & \checkmark \\
	Prepend Zero & \checkmark & \checkmark & \checkmark & \checkmark \\
	Binary Decrement & \checkmark & $x$ & $x$ & $x$ \\
	2BCSR & \checkmark &  & $x$ & \checkmark \\
	Full Adder & \checkmark &  & $x$ & \checkmark \\
	2 Bit Adder & \checkmark &  & x & $x$ \\
	Access & \checkmark & $x$ & \checkmark & \checkmark \\
	Decrement & \checkmark & $x$ & \checkmark & \checkmark \\
\end{tabular}
\caption{Results of all 4 systems on the Basic Execution Models problems from \cite{Gaunt2016}.  A check denotes the system could find a solution. An $x$ denotes the problem was fully posed to the system, but a solution was not found. The G3P system has not been tested on this problem set to our knowledge.}
\label{fig:results1}
\end{figure}

\begin{figure}
\begin{tabular}{ r | c c c c }
	& Flash Fill & MH & PushGP & G3P \\
	\hline
	Number IO & x & \checkmark & \checkmark & \checkmark \\
	Small Or Large & x & x & \checkmark & \checkmark \\
	For Loop Index & x & x & \checkmark & \checkmark \\
	Compare String Lengths & x & x & \checkmark & \checkmark \\
	Double Letters & x & x & \checkmark & x \\
	Collatz Numbers & x & x & x \\
	Replace Space with Newline &   & x & \checkmark & x \\
	String Differences & x & x & x \\
	Even Squares & x & x & \checkmark & \checkmark \\
	Wallis Pi & x & x & x \\
	String Lengths Backwards &   & \checkmark  & \checkmark & \checkmark \\
	Last Index of Zero &  & x & \checkmark & \checkmark \\
	Vector Average &  & \checkmark & \checkmark & x \\
	Count Odds &  & x & \checkmark & \checkmark \\
	Mirror Image &  & x & \checkmark & \checkmark \\
	Super Anagrams & x & x & x & \checkmark \\
	Sum of Squares & x & x & \checkmark & \checkmark \\
	Vectors Summed &  & \checkmark & \checkmark & \checkmark \\
	X-Word Lines & x & x & \checkmark & x \\
	Pig Latin & x & x & x  \\
	Negative To Zero &  & \checkmark & \checkmark & \checkmark \\
	Scrabble Score & x & x & \checkmark & x \\
	Word Stats & x & x & x \\
	Checksum & x & x & \checkmark \\
	Digits & x & x & \checkmark & x \\
	Grade & x & x & \checkmark & \checkmark  \\
	Median & x & x & \checkmark & \checkmark \\
	Smallest & x & \checkmark & \checkmark & \checkmark \\
	Syllables & x & x & \checkmark & x \\
\end{tabular}
\caption{Results of all 3 systems on the Software Synthesis Benchmark Suite from \cite{Helmuth2015b}. A check denotes the system could find a solution. An x denotes the problem was fully posed to the system, but a solution was not found. No symbol denotes the problem could not be fully posed to the system.}
\label{fig:results2}
\end{figure}




\section{Conclusion}

\todo[inline]{What does this mean for applications of IPS.}

\section{Things to mention somewhere}
\begin{itemize}
 \item Differences in runtime
 \item FashFill and MagicHaskeller come up with same thing every time. GP might not.
 \item Can you extract the solution program? Is it readable?
 \item We used boolean vectors as binary tape from TerpreT problems.
 \item We considered the Access problem and the List-k problem to be synonymous in most contexts.
\end{itemize}